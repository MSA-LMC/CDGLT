Starting the task of `metaphor occurrence`...

==========
The timestamp of this experiment: 17377758669428174
==========

Epoch [1/200]
Train Loss:  0.84,  Val Loss:  0.59,  Val Acc: 72.40%,
*Val Macro Avg F1-Score:  0.4199,  Time: 0:00:03
Best Val Macro Avg F1-Score Update!

Mode of test;  Loss:   0.6,  Acc: 71.88%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

     Class 0     0.7188    1.0000    0.8364       575
     Class 1     0.0000    0.0000    0.0000       225

    accuracy                         0.7188       800
   macro avg     0.3594    0.5000    0.4182       800
weighted avg     0.5166    0.7188    0.6011       800

Confusion Matrix...
[[575   0]
 [225   0]]
Time usage: 0:00:01
==========

Epoch [2/200]
Train Loss:  0.61,  Val Loss:  0.58,  Val Acc: 72.40%,
*Val Macro Avg F1-Score:  0.4199,  Time: 0:00:06
==========

Epoch [3/200]
Train Loss:  0.59,  Val Loss:  0.55,  Val Acc: 72.40%,
*Val Macro Avg F1-Score:  0.4199,  Time: 0:00:08
==========

Epoch [4/200]
Train Loss:  0.53,  Val Loss:  0.44,  Val Acc: 75.39%,
*Val Macro Avg F1-Score:  0.5285,  Time: 0:00:09
Best Val Macro Avg F1-Score Update!

Mode of test;  Loss:  0.45,  Acc: 75.25%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

     Class 0     0.7445    0.9983    0.8529       575
     Class 1     0.9655    0.1244    0.2205       225

    accuracy                         0.7525       800
   macro avg     0.8550    0.5614    0.5367       800
weighted avg     0.8067    0.7525    0.6750       800

Confusion Matrix...
[[574   1]
 [197  28]]
Time usage: 0:00:01
==========

Epoch [5/200]
Train Loss:  0.37,  Val Loss:  0.29,  Val Acc: 89.84%,
*Val Macro Avg F1-Score:  0.8622,  Time: 0:00:12
Best Val Macro Avg F1-Score Update!

Mode of test;  Loss:  0.28,  Acc: 90.25%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

     Class 0     0.8976    0.9757    0.9350       575
     Class 1     0.9200    0.7156    0.8050       225

    accuracy                         0.9025       800
   macro avg     0.9088    0.8456    0.8700       800
weighted avg     0.9039    0.9025    0.8984       800

Confusion Matrix...
[[561  14]
 [ 64 161]]
Time usage: 0:00:01
==========

Epoch [6/200]
Train Loss:  0.27,  Val Loss:  0.25,  Val Acc: 90.89%,
*Val Macro Avg F1-Score:  0.8793,  Time: 0:00:14
Best Val Macro Avg F1-Score Update!

Mode of test;  Loss:  0.24,  Acc: 90.88%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

     Class 0     0.9169    0.9600    0.9380       575
     Class 1     0.8838    0.7778    0.8274       225

    accuracy                         0.9087       800
   macro avg     0.9004    0.8689    0.8827       800
weighted avg     0.9076    0.9087    0.9069       800

Confusion Matrix...
[[552  23]
 [ 50 175]]
Time usage: 0:00:00
==========

Epoch [7/200]
Train Loss:  0.22,  Val Loss:  0.29,  Val Acc: 89.06%,
*Val Macro Avg F1-Score:  0.8624,  Time: 0:00:17
==========

Epoch [8/200]
Train Loss:  0.19,  Val Loss:   0.3,  Val Acc: 89.32%,
*Val Macro Avg F1-Score:   0.866,  Time: 0:00:19
==========

Epoch [9/200]
Train Loss:  0.16,  Val Loss:  0.34,  Val Acc: 89.45%,
*Val Macro Avg F1-Score:  0.8659,  Time: 0:00:21
==========

Epoch [10/200]
Train Loss:  0.13,  Val Loss:  0.35,  Val Acc: 89.32%,
*Val Macro Avg F1-Score:  0.8672,  Time: 0:00:23
==========

Epoch [11/200]
Train Loss:  0.12,  Val Loss:  0.56,  Val Acc: 84.90%,
*Val Macro Avg F1-Score:  0.8234,  Time: 0:00:25
==========

Epoch [12/200]
Train Loss:   0.1,  Val Loss:  0.47,  Val Acc: 88.54%,
*Val Macro Avg F1-Score:  0.8613,  Time: 0:00:27
==========

Epoch [13/200]
Train Loss:  0.11,  Val Loss:  0.53,  Val Acc: 86.20%,
*Val Macro Avg F1-Score:  0.8359,  Time: 0:00:29
==========

Epoch [14/200]
Train Loss: 0.079,  Val Loss:  0.55,  Val Acc: 85.94%,
*Val Macro Avg F1-Score:  0.8337,  Time: 0:00:31
==========

Epoch [15/200]
Train Loss: 0.074,  Val Loss:  0.55,  Val Acc: 88.67%,
*Val Macro Avg F1-Score:  0.8605,  Time: 0:00:33
==========

Epoch [16/200]
Train Loss:  0.08,  Val Loss:  0.71,  Val Acc: 86.07%,
*Val Macro Avg F1-Score:  0.8358,  Time: 0:00:35
==========

Epoch [17/200]
Train Loss: 0.077,  Val Loss:  0.47,  Val Acc: 89.71%,
*Val Macro Avg F1-Score:    0.87,  Time: 0:00:37
==========

Epoch [18/200]
Train Loss:   0.1,  Val Loss:  0.42,  Val Acc: 89.84%,
*Val Macro Avg F1-Score:  0.8702,  Time: 0:00:39
==========

Epoch [19/200]
Train Loss:   0.1,  Val Loss:  0.42,  Val Acc: 90.10%,
*Val Macro Avg F1-Score:  0.8632,  Time: 0:00:42
==========

Epoch [20/200]
Train Loss:  0.15,  Val Loss:  0.41,  Val Acc: 89.84%,
*Val Macro Avg F1-Score:   0.858,  Time: 0:00:44
==========

Epoch [21/200]
Train Loss:  0.15,  Val Loss:  0.43,  Val Acc: 88.54%,
*Val Macro Avg F1-Score:  0.8602,  Time: 0:00:46
==========

Epoch [22/200]
Train Loss: 0.065,  Val Loss:  0.44,  Val Acc: 89.71%,
*Val Macro Avg F1-Score:  0.8719,  Time: 0:00:49
==========

Epoch [23/200]
Train Loss: 0.056,  Val Loss:  0.51,  Val Acc: 88.28%,
*Val Macro Avg F1-Score:  0.8563,  Time: 0:00:52
==========

Epoch [24/200]
Train Loss: 0.051,  Val Loss:   0.5,  Val Acc: 88.67%,
*Val Macro Avg F1-Score:  0.8605,  Time: 0:00:54
==========

Epoch [25/200]
Train Loss: 0.048,  Val Loss:  0.52,  Val Acc: 88.80%,
*Val Macro Avg F1-Score:  0.8619,  Time: 0:00:57
==========

Epoch [26/200]
Train Loss: 0.046,  Val Loss:  0.52,  Val Acc: 88.93%,
*Val Macro Avg F1-Score:  0.8633,  Time: 0:01:00
==========


No optimization for a long time, auto-stopping...
So, model in epoch 6 should be chosen for test
The timestamp of this experiment: 17377758669428174
